{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os , glob\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas_montecarlo\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import hvplot.pandas\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the FMP API Key\n",
    "load_dotenv()\n",
    "#Retrive environment variable and store in Python variable\n",
    "api_key= os.getenv('FMP_API_KEY')\n",
    "#confirm retrieval of api key\n",
    "type(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_symbol = ['BTCUSD','LTCUSD','ETHUSD','XRPUSD']\n",
    "url = (f'https://financialmodelingprep.com/api/v3/historical-price-full/crypto/{crypto_symbol}?apikey={api_key}')\n",
    "sp_url = (\"https://financialmodelingprep.com/api/v3/historical-price-full/index/%5EGSPC?apikey=b79521d0a15483a6c556d71f892d0be4\")\n",
    "filepath_1 = Path(\"Data/GC_close_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Historical data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crypto_data(cryptourl):\n",
    "    \"\"\"\n",
    "        Returns the crypto data from the specified URL as parameter.\n",
    "\n",
    "    \"\"\"\n",
    "    #get companies based on criteria defined about\n",
    "    CryptoUSD = requests.get(url)\n",
    "    CryptoUSD = CryptoUSD.json()    \n",
    "    CryptoUSD = CryptoUSD['historical']\n",
    "    Crypto = pd.DataFrame.from_dict(CryptoUSD)\n",
    "    #Crypto['date'] = pd.to_datetime(Crypto['date'])\n",
    "    Crypto.set_index('date',inplace=True)    \n",
    "    #Keep only the close column- Open, close, adjclose, volume,chanepercent\n",
    "    columns =['change','high','label','low','unadjustedVolume','vwap','changeOverTime','close']\n",
    "    Crypto= Crypto.drop(columns, axis=1)    \n",
    "    #Rename the column adjclose and changepercent to close and percentchange\n",
    "    Crypto.rename(columns = {'adjClose' : 'close' , 'changePercent' : 'change%'}, inplace = True)\n",
    "    return Crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveto_csv(dataFrame,fileName):    \n",
    "    newfilename= \"Data\\\\\"  + fileName +\".csv\"    \n",
    "    dataFrame.to_csv(newfilename,index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_daily_to_monthly(df):\n",
    "    #Resample dataframe in order to get monthly prices     \n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df=df.resample('M').mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(csvFilelist,outputfile):\n",
    "    i = len(csvFilelist)\n",
    "    for file in csvFilelist:\n",
    "        # read first file\n",
    "        file1 = pd.read_csv(\"Data\\\\\"+file)\n",
    "        #read second file\n",
    "        file2 = pd.read_csv(csvFile2)\n",
    "        concate_data = pd.concat([file1,file2],index=date)\n",
    "        concate_data.head()\n",
    "        print(\"merged data file\",merged_data.head())\n",
    "    return merged_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in crypto_symbol:\n",
    "    url = (f'https://financialmodelingprep.com/api/v3/historical-price-full/crypto/{symbol}?apikey={api_key}')\n",
    "    crypto_df= get_crypto_data(url)\n",
    "    saveto_csv(crypto_df,symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crypto_returns(csvFile):   \n",
    "    # set the file path\n",
    "    file_path = Path(csvFile)\n",
    "    # create a Pandas DataFrame from a csv file\n",
    "    df = pd.read_csv(file_path)   \n",
    "    # drop null values\n",
    "    df = df.dropna().copy()   \n",
    "    #set date as index\n",
    "    df = df.set_index(\"date\")\n",
    "    # drop all columns except close\n",
    "    columns =['open','volume']\n",
    "    df = df.drop(columns, axis=1)\n",
    "    #rename column\n",
    "    columnname = symbol[:-3]\n",
    "    df.rename(columns = {'close' : columnname}, inplace = True)  \n",
    "    df.rename(columns = {'change%' : columnname+'_change%'}, inplace = True) \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sp500_daily():\n",
    "    sp500daily = requests.get(sp_url)\n",
    "    sp500daily = sp500daily.json()\n",
    "    sp500daily = sp500daily['historical']\n",
    "    sp500_d_change = pd.DataFrame.from_dict(sp500daily)\n",
    "    sp500_d_change.set_index('date', inplace = True)\n",
    "    columns =['change','high', 'volume', 'open', 'label','low','unadjustedVolume', 'vwap','changeOverTime', 'close']\n",
    "    sp500_d_change = sp500_d_change.drop(columns, axis=1)\n",
    "    sp500_d_change.rename(columns = {'adjClose' : 'close', 'changePercent' : 'change%'}, inplace = True)\n",
    "    sp500_d_change.to_csv('Data/daily_sp500_returns.csv')\n",
    "    return sp500_d_change\n",
    "\n",
    "def get_sp500_monthly():    \n",
    "    sp500monthly = requests.get(url)\n",
    "    sp500monthly = sp500monthly.json()\n",
    "    sp500monthly = sp500monthly['historical']\n",
    "    sp_m_change = pd.DataFrame.from_dict(sp500monthly)\n",
    "    columns =['change','high','label','low','unadjustedVolume', 'vwap','changeOverTime', 'close']    \n",
    "    sp_m_change = sp_m_change.drop(columns, axis=1)\n",
    "    sp_m_change.rename(columns = {'adjClose' : 'close', 'changePercent' : 'change%'}, inplace = True)\n",
    "    sp_m_change.set_index('date', inplace=True)\n",
    "    sp_m_change.index = pd.to_datetime(sp_m_change.index)\n",
    "    sp_m_change = sp_m_change.resample('1M').mean()\n",
    "    sp_m_change.to_csv('Data/monthly_sp500_returns.csv')    \n",
    "    return sp_m_change\n",
    "\n",
    "def get_sp_data():     \n",
    "    get_sp500_daily()\n",
    "    get_sp500_monthly()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change DateTime Format\n",
    "def get_gold_data()    \n",
    "    gold_df = pd.read_csv(filepath_1,index_col=\"Date\",parse_dates=True,infer_datetime_format=True)\n",
    "    gold_df.reset_index()\n",
    "    gold_df['Date']= pd.to_datetime(gold_df['Date'])\n",
    "    gold_df['Date'] = gold_df['Date'].dt.strftime(\"%Y/%m/%d\")\n",
    "    #Set Index\n",
    "    gold_df.set_index(pd.to_datetime(gold_df['Date'], infer_datetime_format=True), inplace=True)\n",
    "    gold_df.drop(columns=['Date'], inplace=True)\n",
    "    gold_df.rename(columns={'Close/Last': 'Gold_Close'},inplace = True)\n",
    "    return gold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_returns()\n",
    "    #Calculate daily Gold returns\n",
    "    gold_returns = get_gold_data()\n",
    "    gold_returns.drop(columns=['Open','High','Volume','Low'], inplace=True)\n",
    "    gold_returns = gold_returns.pct_change()\n",
    "    #Rename columns\n",
    "    gold_returns.rename(columns={'Gold_Close':'Gold_Rate%'},inplace = True)\n",
    "    return gold_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_silver_data()    \n",
    "    # Reading Silver returns\n",
    "    filepath_2 = Path(\"Data/SI_close_prices.csv\")\n",
    "    silver_df = pd.read_csv(filepath_2)\n",
    "    #Change DateTime Format\n",
    "    silver_df['Date']= pd.to_datetime(silver_df['Date'])\n",
    "    silver_df['Date']= silver_df['Date'].dt.strftime(\"%Y/%m/%d\")\n",
    "    #Set Index\n",
    "    silver_df.set_index(pd.to_datetime(silver_df['Date'], infer_datetime_format=True), inplace=True)\n",
    "    silver_df.rename(columns={'Close/Last': 'Silver_Close'},inplace = True)\n",
    "    silver_df.drop(columns=['Date'], inplace=True)\n",
    "    return silver_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silver_returns()\n",
    "    #Calculate daily Silver returns\n",
    "    silver_returns = get_silver_data()\n",
    "    silver_returns.drop(columns=['Open','High','Volume','Low'], inplace=True)\n",
    "    silver_returns = silver_returns.pct_change()\n",
    "    #Rename columns\n",
    "    silver_returns.rename(columns={'Silver_Close':'Silver_Rate%'},inplace = True)\n",
    "    return silver_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_treaury_data()\n",
    "    Daily_US_Treasury_Yield = Path('Data/US Daily Yield.csv')\n",
    "    Daily_US_Treasury_Yield_DF = pd.read_csv(Daily_US_Treasury_Yield, index_col = \"Date\", parse_dates=True, infer_datetime_format=True)\n",
    "    Daily_US_Treasury_Yield_DF.head(10)\n",
    "    five_year = Daily_US_Treasury_Yield_DF['5 Yr']\n",
    "    five_year_df = pd.DataFrame(data = five_year)\n",
    "    five_year_df.plot.line(figsize = (15,7), title = \"Daily Yield Changes in US Treasury Bonds, 2015 - 2020\")\n",
    "    return five_year_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sp_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in crypto_symbol: \n",
    "    csvFile = 'Data\\\\'+symbol+'.csv'\n",
    "    if symbol == 'BTCUSD':\n",
    "        btc_df=get_crypto_returns(csvFile)       \n",
    "    elif symbol == 'LTCUSD':\n",
    "        ltc_df=get_crypto_returns(csvFile)\n",
    "    elif symbol == 'XRPUSD':\n",
    "        xrp_df=get_crypto_returns(csvFile)\n",
    "    elif symbol == 'ETHUSD':\n",
    "        etc_df=get_crypto_returns(csvFile)    \n",
    "\n",
    "combine_crypto_df = pd.concat([btc_df,ltc_df,xrp_df,etc_df], axis = 'columns', join='inner')\n",
    "saveto_csv(combine_crypto_df,'daily_cryptoall')\n",
    "monthly_crypto_df=convert_daily_to_monthly(combine_crypto_df)\n",
    "saveto_csv(monthly_crypto_df,'monthly_cryptoall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFilelist=['daily_cryptoall.csv','daily_commodity_df.csv','daily_sp500_returns.csv','daily_bond_data.csv']\n",
    "i = len(csvFilelist)\n",
    "for file in csvFilelist:\n",
    "    if file.startswith('daily_crypto'):\n",
    "        file1 = pd.read_csv(\"Data\\\\\"+file, parse_dates=True, infer_datetime_format=True)\n",
    "        file1=file1.set_index('date')\n",
    "    elif file.startswith('daily_sp500'):\n",
    "        #read second file    \n",
    "        file2 = pd.read_csv(\"Data\\\\\"+file,parse_dates=True, infer_datetime_format=True)         \n",
    "        file2=file2.set_index('date')\n",
    "        file2.rename(columns = {'close' : 'sp500_close','change%' :'sp500_change%'}, inplace = True)        \n",
    "    elif file.startswith('daily_commodity'):\n",
    "        file3 = pd.read_csv(\"Data\\\\\"+file, parse_dates=True, infer_datetime_format=True)\n",
    "        # rename Pandas columns to lower case        \n",
    "        file3.columns= file3.columns.str.lower()\n",
    "        file3 = file3.drop(['open','low','high','volume','open.1','low.1','high.1','volume.1'],axis=1)\n",
    "        file3['date'] = pd.to_datetime(file3['date'], format=\"%d/%m/%Y\")                      \n",
    "        file3=file3.set_index('date')       \n",
    "    else:\n",
    "        file4=pd.read_csv(\"Data\\\\\"+file,parse_dates=True, infer_datetime_format=True)                \n",
    "        file4.columns= file4.columns.str.lower()     \n",
    "        file4['5 yr'] = file4['5 yr'] / 100\n",
    "        file4=file4.set_index('date')        \n",
    "        file4.rename(columns = {'5 yr' : 'bonds5yr_close'}, inplace = True)           \n",
    "    \n",
    "\n",
    "concate_data = pd.merge(file1,file2, on='date', how='inner')\n",
    "merged_df = concate_data.join(file3, how='inner')\n",
    "final_merged_df = merged_df.join(file4, how='inner')\n",
    "saveto_csv(final_merged_df,'daily_combineall')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFilelist=['monthly_cryptoall.csv','monthly_commodity_df.csv','monthly_sp500_returns.csv','monthly_bonds_data.csv']\n",
    "i = len(csvFilelist)\n",
    "for file in csvFilelist:\n",
    "    if file.startswith('monthly_crypto'):\n",
    "        file1 = pd.read_csv(\"Data\\\\\"+file, parse_dates=True, infer_datetime_format=True)\n",
    "        file1=file1.set_index('date')\n",
    "    elif file.startswith('monthly_sp500'):\n",
    "        #read second file    \n",
    "        file2 = pd.read_csv(\"Data\\\\\"+file, parse_dates=True, infer_datetime_format=False)               \n",
    "        file2 = file2.drop(['open','volume'],axis=1)\n",
    "        file2.rename(columns = {'close' : 'sp500_close', 'change%' : 'sp500_change%'}, inplace = True)\n",
    "        file2=file2.set_index('date')\n",
    "    elif file.startswith('monthly_commodity'):\n",
    "        file3 = pd.read_csv(\"Data\\\\\"+file, parse_dates=True, infer_datetime_format=True)\n",
    "        # rename Pandas columns to lower case        \n",
    "        file3.columns= file3.columns.str.lower()\n",
    "        file3 = file3.drop(['open','low','high','open.1','low.1','high.1'],axis=1)\n",
    "        #file3['date'] = pd.to_datetime(file3['date'], format=\"%d/%m/%Y\")   \n",
    "        file3=file3.set_index('date')\n",
    "    else:\n",
    "        file4=pd.read_csv(\"Data\\\\\"+file,parse_dates=True, infer_datetime_format=True)\n",
    "        file4.columns= file4.columns.str.lower()\n",
    "        file4=file4.set_index('date')\n",
    "        file4.rename(columns = {'rate' : 'bonds_close'}, inplace = True)    \n",
    "    \n",
    "\n",
    "concate_monthly = pd.concat([file1,file2,file3,file4],axis='columns', join='inner')\n",
    "saveto_csv(concate_monthly,'monthly_combineall')     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
